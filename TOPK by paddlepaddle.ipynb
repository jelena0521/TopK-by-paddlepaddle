{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduct\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**paddlepaddleæ˜¯ç™¾åº¦å…¬å¸æå‡ºçš„æ¡†æ¶ï¼Œä»‹äºæœ€è¿‘çš„ä¸­ç¾å½¢åŠ¿ï¼Œå­¦ä¹ ä¸€é—¨å›½å†…çš„æ¡†æ¶è§†ä¹å˜å¾—å¾ˆæœ‰å¿…è¦ğŸ˜­**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part1:é¢„å¤„ç†æ•°æ®"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**è¿™é‡Œçš„æ•°æ®é‡‡ç”¨çš„æ˜¯æ¨èä¸­çš„å¸¸ç”¨movielenï¼Œåœ¨åŸæ•°æ®çš„åŸºç¡€ä¸ŠåŠ å…¥æµ·æŠ¥ï¼ˆæ‰€ä»¥æ¨¡å‹ä¸­æœ‰CNN)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle \n",
    "import paddle.fluid as fluid\n",
    "import paddle.fluid.dygraph as dygraph\n",
    "from paddle.fluid.dygraph import FC, Conv2D, Embedding, Pool2D\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "class MovieLen(object):\n",
    "    def __init__(self, use_poster):\n",
    "        self.use_poster = use_poster\n",
    "        usr_info_path = \"data/users.dat\"\n",
    "        if not use_poster:\n",
    "            rating_path = \"data/ratings.dat\"\n",
    "        else:\n",
    "            rating_path = \"data/new_rating.txt\"\n",
    "\n",
    "        movie_info_path = \"data/movies.dat\"\n",
    "        self.poster_path = \"data/posters/\"\n",
    "        # å¾—åˆ°ç”µå½±æ•°æ®\n",
    "        self.movie_info, self.movie_cat, self.movie_title = self.get_movie_info(movie_info_path)\n",
    "        # è®°å½•ç”µå½±çš„æœ€å¤§ID\n",
    "        self.max_mov_cat = np.max([self.movie_cat[k] for k in self.movie_cat])\n",
    "        self.max_mov_tit = np.max([self.movie_title[k] for k in self.movie_title])\n",
    "        self.max_mov_id = np.max(list(map(int, self.movie_info.keys())))\n",
    "        # è®°å½•ç”¨æˆ·æ•°æ®çš„æœ€å¤§ID\n",
    "        self.max_usr_id = 0\n",
    "        self.max_usr_age = 0\n",
    "        self.max_usr_job = 0\n",
    "        # å¾—åˆ°ç”¨æˆ·æ•°æ®\n",
    "        self.usr_info = self.get_usr_info(usr_info_path)\n",
    "        # å¾—åˆ°è¯„åˆ†æ•°æ®\n",
    "        self.rating_info = self.get_rating_info(rating_path)\n",
    "        # æ„å»ºæ•°æ®é›† \n",
    "        self.dataset = self.get_dataset(usr_info=self.usr_info,\n",
    "                                        rating_info=self.rating_info,\n",
    "                                        movie_info=self.movie_info)\n",
    "        # åˆ’åˆ†æ•°æ®åŠï¼Œè·å¾—æ•°æ®åŠ è½½å™¨\n",
    "        self.train_dataset = self.dataset[:int(len(self.dataset)*0.9)]\n",
    "        self.valid_dataset = self.dataset[int(len(self.dataset)*0.9):]\n",
    "        print(\"##Total dataset instances: \", len(self.dataset))\n",
    "        print(\"##MovieLens dataset information: \\nusr num: {}\\n\"\n",
    "              \"movies num: {}\".format(len(self.usr_info),len(self.movie_info)))\n",
    "    # å¾—åˆ°ç”µå½±æ•°æ®\n",
    "    def get_movie_info(self, path):\n",
    "        # æ‰“å¼€æ–‡ä»¶ï¼Œç¼–ç æ–¹å¼é€‰æ‹©ISO-8859-1ï¼Œè¯»å–æ‰€æœ‰æ•°æ®åˆ°dataä¸­ \n",
    "        with open(path, 'r', encoding=\"ISO-8859-1\") as f:\n",
    "            data = f.readlines()\n",
    "        # å»ºç«‹ä¸‰ä¸ªå­—å…¸ï¼Œåˆ†åˆ«ç”¨æˆ·å­˜æ”¾ç”µå½±æ‰€æœ‰ä¿¡æ¯ï¼Œç”µå½±çš„åå­—ä¿¡æ¯ã€ç±»åˆ«ä¿¡æ¯\n",
    "        movie_info, movie_titles, movie_cat = {}, {}, {}\n",
    "        # å¯¹ç”µå½±åå­—ã€ç±»åˆ«ä¸­ä¸åŒçš„å•è¯è®¡æ•°\n",
    "        t_count, c_count = 1, 1\n",
    "\n",
    "        count_tit = {}\n",
    "        # æŒ‰è¡Œè¯»å–æ•°æ®å¹¶å¤„ç†\n",
    "        for item in data:\n",
    "            item = item.strip().split(\"::\")\n",
    "            v_id = item[0]\n",
    "            v_title = item[1][:-7]\n",
    "            cats = item[2].split('|')\n",
    "            v_year = item[1][-5:-1]\n",
    "\n",
    "            titles = v_title.split()\n",
    "            # ç»Ÿè®¡ç”µå½±åå­—çš„å•è¯ï¼Œå¹¶ç»™æ¯ä¸ªå•è¯ä¸€ä¸ªåºå·ï¼Œæ”¾åœ¨movie_titlesä¸­\n",
    "            for t in titles:\n",
    "                if t not in movie_titles:\n",
    "                    movie_titles[t] = t_count\n",
    "                    t_count += 1\n",
    "            # ç»Ÿè®¡ç”µå½±ç±»åˆ«å•è¯ï¼Œå¹¶ç»™æ¯ä¸ªå•è¯ä¸€ä¸ªåºå·ï¼Œæ”¾åœ¨movie_catä¸­\n",
    "            for cat in cats:\n",
    "                if cat not in movie_cat:\n",
    "                    movie_cat[cat] = c_count\n",
    "                    c_count += 1\n",
    "            # è¡¥0ä½¿ç”µå½±åç§°å¯¹åº”çš„åˆ—è¡¨é•¿åº¦ä¸º15\n",
    "            v_tit = [movie_titles[k] for k in titles]\n",
    "            while len(v_tit)<15:\n",
    "                v_tit.append(0)\n",
    "            # è¡¥0ä½¿ç”µå½±ç§ç±»å¯¹åº”çš„åˆ—è¡¨é•¿åº¦ä¸º6\n",
    "            v_cat = [movie_cat[k] for k in cats]\n",
    "            while len(v_cat)<6:\n",
    "                v_cat.append(0)\n",
    "            # ä¿å­˜ç”µå½±æ•°æ®åˆ°movie_infoä¸­\n",
    "            movie_info[v_id] = {'mov_id': int(v_id),\n",
    "                                'title': v_tit,\n",
    "                                'category': v_cat,\n",
    "                                'years': int(v_year)}\n",
    "        return movie_info, movie_cat, movie_titles\n",
    "\n",
    "    def get_usr_info(self, path):\n",
    "        # æ€§åˆ«è½¬æ¢å‡½æ•°ï¼ŒM-0ï¼Œ F-1\n",
    "        def gender2num(gender):\n",
    "            return 1 if gender == 'F' else 0\n",
    "\n",
    "        # æ‰“å¼€æ–‡ä»¶ï¼Œè¯»å–æ‰€æœ‰è¡Œåˆ°dataä¸­\n",
    "        with open(path, 'r') as f:\n",
    "            data = f.readlines()\n",
    "        # å»ºç«‹ç”¨æˆ·ä¿¡æ¯çš„å­—å…¸\n",
    "        use_info = {}\n",
    "\n",
    "        max_usr_id = 0\n",
    "        #æŒ‰è¡Œç´¢å¼•æ•°æ®\n",
    "        for item in data:\n",
    "            # å»é™¤æ¯ä¸€è¡Œä¸­å’Œæ•°æ®æ— å…³çš„éƒ¨åˆ†\n",
    "            item = item.strip().split(\"::\")\n",
    "            usr_id = item[0]\n",
    "            # å°†å­—ç¬¦æ•°æ®è½¬æˆæ•°å­—å¹¶ä¿å­˜åœ¨å­—å…¸ä¸­\n",
    "            use_info[usr_id] = {'usr_id': int(usr_id),\n",
    "                                'gender': gender2num(item[1]),\n",
    "                                'age': int(item[2]),\n",
    "                                'job': int(item[3])}\n",
    "            self.max_usr_id = max(self.max_usr_id, int(usr_id))\n",
    "            self.max_usr_age = max(self.max_usr_age, int(item[2]))\n",
    "            self.max_usr_job = max(self.max_usr_job, int(item[3]))\n",
    "        return use_info\n",
    "    # å¾—åˆ°è¯„åˆ†æ•°æ®\n",
    "    def get_rating_info(self, path):\n",
    "        # è¯»å–æ–‡ä»¶é‡Œçš„æ•°æ®\n",
    "        with open(path, 'r') as f:\n",
    "            data = f.readlines()\n",
    "        # å°†æ•°æ®ä¿å­˜åœ¨å­—å…¸ä¸­å¹¶è¿”å›\n",
    "        rating_info = {}\n",
    "        for item in data:\n",
    "            item = item.strip().split(\"::\")\n",
    "            usr_id,movie_id,score = item[0],item[1],item[2]\n",
    "            if usr_id not in rating_info.keys():\n",
    "                rating_info[usr_id] = {movie_id:float(score)}\n",
    "            else:\n",
    "                rating_info[usr_id][movie_id] = float(score)\n",
    "        return rating_info\n",
    "    # æ„å»ºæ•°æ®é›†\n",
    "    def get_dataset(self, usr_info, rating_info, movie_info):\n",
    "        trainset = []\n",
    "        for usr_id in rating_info.keys():\n",
    "            usr_ratings = rating_info[usr_id]\n",
    "            for movie_id in usr_ratings:\n",
    "                trainset.append({'usr_info': usr_info[usr_id],\n",
    "                                 'mov_info': movie_info[movie_id],\n",
    "                                 'scores': usr_ratings[movie_id]})\n",
    "        return trainset\n",
    "    \n",
    "    def load_data(self, dataset=None, mode='train'):\n",
    "        use_poster = False\n",
    "\n",
    "        # å®šä¹‰æ•°æ®è¿­ä»£Batchå¤§å°\n",
    "        BATCHSIZE = 256\n",
    "\n",
    "        data_length = len(dataset)\n",
    "        index_list = list(range(data_length))\n",
    "        # å®šä¹‰æ•°æ®è¿­ä»£åŠ è½½å™¨\n",
    "        def data_generator():\n",
    "            # è®­ç»ƒæ¨¡å¼ä¸‹ï¼Œæ‰“ä¹±è®­ç»ƒæ•°æ®\n",
    "            if mode == 'train':\n",
    "                random.shuffle(index_list)\n",
    "            # å£°æ˜æ¯ä¸ªç‰¹å¾çš„åˆ—è¡¨\n",
    "            usr_id_list,usr_gender_list,usr_age_list,usr_job_list = [], [], [], []\n",
    "            mov_id_list,mov_tit_list,mov_cat_list,mov_poster_list = [], [], [], []\n",
    "            score_list = []\n",
    "            # ç´¢å¼•éå†è¾“å…¥æ•°æ®é›†\n",
    "            for idx, i in enumerate(index_list):\n",
    "                # è·å¾—ç‰¹å¾æ•°æ®ä¿å­˜åˆ°å¯¹åº”ç‰¹å¾åˆ—è¡¨ä¸­\n",
    "                usr_id_list.append(dataset[i]['usr_info']['usr_id'])\n",
    "                usr_gender_list.append(dataset[i]['usr_info']['gender'])\n",
    "                usr_age_list.append(dataset[i]['usr_info']['age'])\n",
    "                usr_job_list.append(dataset[i]['usr_info']['job'])\n",
    "\n",
    "                mov_id_list.append(dataset[i]['mov_info']['mov_id'])\n",
    "                mov_tit_list.append(dataset[i]['mov_info']['title'])\n",
    "                mov_cat_list.append(dataset[i]['mov_info']['category'])\n",
    "                mov_id = dataset[i]['mov_info']['mov_id']\n",
    "\n",
    "                if use_poster:\n",
    "                    # ä¸ä½¿ç”¨å›¾åƒç‰¹å¾æ—¶ï¼Œä¸è¯»å–å›¾åƒæ•°æ®ï¼ŒåŠ å¿«æ•°æ®è¯»å–é€Ÿåº¦\n",
    "                    poster = Image.open(self.poster_path+'mov_id{}.jpg'.format(str(mov_id[0])))\n",
    "                    poster = poster.resize([64, 64])\n",
    "                    if len(poster.size) <= 2:\n",
    "                        poster = poster.convert(\"RGB\")\n",
    "\n",
    "                    mov_poster_list.append(np.array(poster))\n",
    "\n",
    "                score_list.append(int(dataset[i]['scores']))\n",
    "                # å¦‚æœè¯»å–çš„æ•°æ®é‡è¾¾åˆ°å½“å‰çš„batchå¤§å°ï¼Œå°±è¿”å›å½“å‰æ‰¹æ¬¡\n",
    "                if len(usr_id_list)==BATCHSIZE:\n",
    "                    # è½¬æ¢åˆ—è¡¨æ•°æ®ä¸ºæ•°ç»„å½¢å¼ï¼Œreshapeåˆ°å›ºå®šå½¢çŠ¶\n",
    "                    usr_id_arr = np.expand_dims(np.array(usr_id_list), axis=-1)\n",
    "                    usr_gender_arr = np.expand_dims(np.array(usr_gender_list), axis=-1)\n",
    "                    usr_age_arr = np.expand_dims(np.array(usr_age_list), axis=-1)\n",
    "                    usr_job_arr = np.expand_dims(np.array(usr_job_list), axis=-1)\n",
    "\n",
    "                    mov_id_arr = np.expand_dims(np.array(mov_id_list), axis=-1)\n",
    "                    mov_cat_arr = np.reshape(np.array(mov_cat_list), [BATCHSIZE, 1, 6, 1]).astype(np.int64)\n",
    "                    mov_tit_arr = np.reshape(np.array(mov_tit_list), [BATCHSIZE, 1, 15, 1]).astype(np.int64)\n",
    "\n",
    "\n",
    "                    if use_poster:\n",
    "                        mov_poster_arr = np.reshape(np.array(mov_poster_list)/127.5 - 1, [BATCHSIZE, 3, 64, 64]).astype(np.float32)\n",
    "                    else:\n",
    "                        mov_poster_arr = np.array([0.])\n",
    "\n",
    "                    scores_arr = np.reshape(np.array(score_list), [-1, 1]).astype(np.float32)\n",
    "\n",
    "                    # æ”¾å›å½“å‰æ‰¹æ¬¡æ•°æ®\n",
    "                    yield [usr_id_arr, usr_gender_arr, usr_age_arr, usr_job_arr], \\\n",
    "                           [mov_id_arr, mov_cat_arr, mov_tit_arr, mov_poster_arr], scores_arr\n",
    "\n",
    "                    # æ¸…ç©ºæ•°æ®\n",
    "                    usr_id_list, usr_gender_list, usr_age_list, usr_job_list = [], [], [], []\n",
    "                    mov_id_list, mov_tit_list, mov_cat_list, score_list = [], [], [], []\n",
    "                    mov_poster_list = []\n",
    "        return data_generator\n",
    "\n",
    "class Model(dygraph.layers.Layer):\n",
    "    def __init__(self, name_scope, use_poster, use_mov_title, use_mov_cat, use_age_job):\n",
    "        super(Model, self).__init__(name_scope)\n",
    "        name = self.full_name()\n",
    "        \n",
    "        # å°†ä¼ å…¥çš„nameä¿¡æ¯å’Œboolå‹å‚æ•°æ·»åŠ åˆ°æ¨¡å‹ç±»ä¸­\n",
    "        self.use_mov_poster = use_poster\n",
    "        self.use_mov_title = use_mov_title\n",
    "        self.use_usr_age_job = use_age_job\n",
    "        self.use_mov_cat = use_mov_cat\n",
    "        \n",
    "        # è·å–æ•°æ®é›†çš„ä¿¡æ¯ï¼Œå¹¶æ„å»ºè®­ç»ƒå’ŒéªŒè¯é›†çš„æ•°æ®è¿­ä»£å™¨\n",
    "        Dataset = MovieLen(self.use_mov_poster)\n",
    "        self.Dataset = Dataset\n",
    "        self.trainset = self.Dataset.train_dataset\n",
    "        self.valset = self.Dataset.valid_dataset\n",
    "        self.train_loader = self.Dataset.load_data(dataset=self.trainset, mode='train')\n",
    "        self.valid_loader = self.Dataset.load_data(dataset=self.valset, mode='valid')\n",
    "\n",
    "        \"\"\" define network layer for embedding usr info \"\"\"\n",
    "        USR_ID_NUM = Dataset.max_usr_id + 1\n",
    "        # å¯¹ç”¨æˆ·IDåšæ˜ å°„ï¼Œå¹¶ç´§æ¥ç€ä¸€ä¸ªFCå±‚\n",
    "        self.usr_emb = Embedding(name, [USR_ID_NUM, 32], is_sparse=False)\n",
    "        self.usr_fc = FC(name, size=32)\n",
    "        \n",
    "        # å¯¹ç”¨æˆ·æ€§åˆ«ä¿¡æ¯åšæ˜ å°„ï¼Œå¹¶ç´§æ¥ç€ä¸€ä¸ªFCå±‚\n",
    "        USR_GENDER_DICT_SIZE = 2\n",
    "        self.usr_gender_emb = Embedding(name, [USR_GENDER_DICT_SIZE, 16])\n",
    "        self.usr_gender_fc = FC(name, 16)\n",
    "        \n",
    "        # å¯¹ç”¨æˆ·å¹´é¾„ä¿¡æ¯åšæ˜ å°„ï¼Œå¹¶ç´§æ¥ç€ä¸€ä¸ªFCå±‚\n",
    "        USR_AGE_DICT_SIZE = Dataset.max_usr_age + 1\n",
    "        self.usr_age_emb = Embedding(name, [USR_AGE_DICT_SIZE, 16])\n",
    "        self.usr_age_fc = FC(name, 16)\n",
    "        \n",
    "        # å¯¹ç”¨æˆ·èŒä¸šä¿¡æ¯åšæ˜ å°„ï¼Œå¹¶ç´§æ¥ç€ä¸€ä¸ªFCå±‚\n",
    "        USR_JOB_DICT_SIZE = Dataset.max_usr_job + 1\n",
    "        self.usr_job_emb = Embedding(name, [USR_JOB_DICT_SIZE, 16])\n",
    "        self.usr_job_fc = FC(name, 16)\n",
    "        \n",
    "        # æ–°å»ºä¸€ä¸ªFCå±‚ï¼Œç”¨äºæ•´åˆç”¨æˆ·æ•°æ®ä¿¡æ¯\n",
    "        self.usr_combined = FC(name, 200, act='tanh')\n",
    "        \n",
    "        \"\"\" define network layer for embedding usr info \"\"\"\n",
    "        # å¯¹ç”µå½±IDä¿¡æ¯åšæ˜ å°„ï¼Œå¹¶ç´§æ¥ç€ä¸€ä¸ªFCå±‚\n",
    "        MOV_DICT_SIZE = Dataset.max_mov_id + 1\n",
    "        self.mov_emb = Embedding(name, [MOV_DICT_SIZE, 32])\n",
    "        self.mov_fc = FC(name, 32)\n",
    "        \n",
    "        # å¯¹ç”µå½±ç±»åˆ«åšæ˜ å°„\n",
    "        CATEGORY_DICT_SIZE = len(Dataset.movie_cat) + 1\n",
    "        self.mov_cat_emb = Embedding(name, [CATEGORY_DICT_SIZE, 32], is_sparse=False)\n",
    "        self.mov_cat_fc = FC(name, 32)\n",
    "        \n",
    "        # å¯¹ç”µå½±åç§°åšæ˜ å°„\n",
    "        MOV_TITLE_DICT_SIZE = len(Dataset.movie_title) + 1\n",
    "        self.mov_title_emb = Embedding(name, [MOV_TITLE_DICT_SIZE, 32], is_sparse=False)\n",
    "        self.mov_title_conv = Conv2D(name, 1, filter_size=(3, 1), stride=(2,1), padding=0, act='relu')\n",
    "        self.mov_title_conv2 = Conv2D(name, 1, filter_size=(3, 1), stride=1, padding=0, act='relu')\n",
    "        \n",
    "        # æ–°å»ºä¸€ä¸ªFCå±‚ï¼Œç”¨äºæ•´åˆç”µå½±ç‰¹å¾\n",
    "        self.mov_concat_embed = FC(name, size=200, act='tanh')\n",
    "        \n",
    "    # å®šä¹‰è®¡ç®—ç”¨æˆ·ç‰¹å¾çš„å‰å‘è¿ç®—è¿‡ç¨‹\n",
    "    def get_usr_feat(self, usr_var):\n",
    "        \"\"\" get usr features\"\"\"\n",
    "        # è·å–åˆ°ç”¨æˆ·æ•°æ®\n",
    "        usr_id, usr_gender, usr_age, usr_job = usr_var\n",
    "        # å°†ç”¨æˆ·çš„IDæ•°æ®ç»è¿‡embeddingå’ŒFCè®¡ç®—ï¼Œå¾—åˆ°çš„ç‰¹å¾ä¿å­˜åœ¨feats_collectä¸­\n",
    "        feats_collect = []\n",
    "        usr_id = self.usr_emb(usr_id)\n",
    "        usr_id = self.usr_fc(usr_id)\n",
    "        usr_id = fluid.layers.relu(usr_id)\n",
    "        feats_collect.append(usr_id)\n",
    "        \n",
    "        # è®¡ç®—ç”¨æˆ·çš„æ€§åˆ«ç‰¹å¾ï¼Œå¹¶ä¿å­˜åœ¨feats_collectä¸­\n",
    "        usr_gender = self.usr_gender_emb(usr_gender)\n",
    "        usr_gender = self.usr_gender_fc(usr_gender)\n",
    "        usr_gender = fluid.layers.relu(usr_gender)\n",
    "        feats_collect.append(usr_gender)\n",
    "        # é€‰æ‹©æ˜¯å¦ä½¿ç”¨ç”¨æˆ·çš„å¹´é¾„-èŒä¸šç‰¹å¾\n",
    "        if self.use_usr_age_job:\n",
    "            # è®¡ç®—ç”¨æˆ·çš„å¹´é¾„ç‰¹å¾ï¼Œå¹¶ä¿å­˜åœ¨feats_collectä¸­\n",
    "            usr_age = self.usr_age_emb(usr_age)\n",
    "            usr_age = self.usr_age_fc(usr_age)\n",
    "            usr_age = fluid.layers.relu(usr_age)\n",
    "            feats_collect.append(usr_age)\n",
    "            # è®¡ç®—ç”¨æˆ·çš„èŒä¸šç‰¹å¾ï¼Œå¹¶ä¿å­˜åœ¨feats_collectä¸­\n",
    "            usr_job = self.usr_job_emb(usr_job)\n",
    "            usr_job = self.usr_job_fc(usr_job)\n",
    "            usr_job = fluid.layers.relu(usr_job)\n",
    "            feats_collect.append(usr_job)\n",
    "        \n",
    "        # å°†ç”¨æˆ·çš„ç‰¹å¾çº§è”ï¼Œå¹¶é€šè¿‡FCå±‚å¾—åˆ°æœ€ç»ˆçš„ç”¨æˆ·ç‰¹å¾\n",
    "        usr_feat = fluid.layers.concat(feats_collect, axis=1)\n",
    "        usr_feat = self.usr_combined(usr_feat)\n",
    "        return usr_feat\n",
    "\n",
    "        # å®šä¹‰ç”µå½±ç‰¹å¾çš„å‰å‘è®¡ç®—è¿‡ç¨‹\n",
    "    def get_mov_feat(self, mov_var):\n",
    "        \"\"\" get movie features\"\"\"\n",
    "        # è·å¾—ç”µå½±æ•°æ®\n",
    "        mov_id, mov_cat, mov_title, mov_poster = mov_var\n",
    "        feats_collect = []\n",
    "        # è·å¾—batchsizeçš„å¤§å°\n",
    "        batch_size = mov_id.shape[0]\n",
    "        # è®¡ç®—ç”µå½±IDçš„ç‰¹å¾ï¼Œå¹¶å­˜åœ¨feats_collectä¸­\n",
    "        mov_id = self.mov_emb(mov_id)\n",
    "        mov_id = self.mov_fc(mov_id)\n",
    "        mov_id = fluid.layers.relu(mov_id)\n",
    "        feats_collect.append(mov_id)\n",
    "        \n",
    "        # å¦‚æœä½¿ç”¨ç”µå½±çš„ç§ç±»æ•°æ®ï¼Œè®¡ç®—ç”µå½±ç§ç±»ç‰¹å¾çš„æ˜ å°„\n",
    "        if self.use_mov_cat:\n",
    "            # è®¡ç®—ç”µå½±ç§ç±»çš„ç‰¹å¾æ˜ å°„ï¼Œå¯¹å¤šä¸ªç§ç±»çš„ç‰¹å¾æ±‚å’Œå¾—åˆ°æœ€ç»ˆç‰¹å¾\n",
    "            mov_cat = self.mov_cat_emb(mov_cat)\n",
    "            mov_cat = fluid.layers.reduce_sum(mov_cat, dim=1, keep_dim=False)\n",
    "\n",
    "            mov_cat = self.mov_cat_fc(mov_cat)\n",
    "            feats_collect.append(mov_cat)\n",
    "\n",
    "        if self.use_mov_title:\n",
    "            # è®¡ç®—ç”µå½±åå­—çš„ç‰¹å¾æ˜ å°„ï¼Œå¯¹ç‰¹å¾æ˜ å°„ä½¿ç”¨å·ç§¯è®¡ç®—æœ€ç»ˆçš„ç‰¹å¾\n",
    "            mov_title = self.mov_title_emb(mov_title)\n",
    "            mov_title = self.mov_title_conv2(self.mov_title_conv(mov_title))\n",
    "            mov_title = fluid.layers.reduce_sum(mov_title, dim=2, keep_dim=False)\n",
    "            mov_title = fluid.layers.relu(mov_title)\n",
    "            mov_title = fluid.layers.reshape(mov_title, [batch_size, -1])\n",
    "            feats_collect.append(mov_title)\n",
    "            \n",
    "        # ä½¿ç”¨ä¸€ä¸ªå…¨è¿æ¥å±‚ï¼Œæ•´åˆæ‰€æœ‰ç”µå½±ç‰¹å¾ï¼Œæ˜ å°„ä¸ºä¸€ä¸ª200ç»´çš„ç‰¹å¾å‘é‡\n",
    "        mov_feat = fluid.layers.concat(feats_collect, axis=1)\n",
    "        mov_feat = self.mov_concat_embed(mov_feat)\n",
    "        return mov_feat\n",
    "    \n",
    "    # å®šä¹‰ä¸ªæ€§åŒ–æ¨èç®—æ³•çš„å‰å‘è®¡ç®—\n",
    "    def forward(self, usr_var, mov_var):\n",
    "        # è®¡ç®—ç”¨æˆ·ç‰¹å¾å’Œç”µå½±ç‰¹å¾\n",
    "        usr_feat = self.get_usr_feat(usr_var)\n",
    "        mov_feat = self.get_mov_feat(mov_var)\n",
    "        # æ ¹æ®è®¡ç®—çš„ç‰¹å¾è®¡ç®—ç›¸ä¼¼åº¦\n",
    "        res = fluid.layers.cos_sim(usr_feat, mov_feat)\n",
    "        # å°†ç›¸ä¼¼åº¦æ‰©å¤§èŒƒå›´åˆ°å’Œç”µå½±è¯„åˆ†ç›¸åŒæ•°æ®èŒƒå›´\n",
    "        res = fluid.layers.scale(res, scale=5)\n",
    "        return usr_feat, mov_feat, res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part2:è®­ç»ƒæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    # é…ç½®è®­ç»ƒå‚æ•°\n",
    "    use_gpu = False\n",
    "    lr = 0.01\n",
    "    Epoches = 10\n",
    "\n",
    "    place = fluid.CUDAPlace(0) if use_gpu else fluid.CPUPlace()\n",
    "    with fluid.dygraph.guard(place):\n",
    "        # å¯åŠ¨è®­ç»ƒ\n",
    "        model.train()\n",
    "        # è·å¾—æ•°æ®è¯»å–å™¨\n",
    "        data_loader = model.train_loader\n",
    "        # ä½¿ç”¨adamä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡ä½¿ç”¨0.01\n",
    "        opt = fluid.optimizer.Adam(learning_rate=lr)\n",
    "        \n",
    "        for epoch in range(0, Epoches):\n",
    "            for idx, data in enumerate(data_loader()):\n",
    "                # è·å¾—æ•°æ®ï¼Œå¹¶è½¬ä¸ºåŠ¨æ€å›¾æ ¼å¼\n",
    "                usr, mov, score = data\n",
    "                usr_v = [dygraph.to_variable(var) for var in usr]\n",
    "                mov_v = [dygraph.to_variable(var) for var in mov]\n",
    "                scores_label = dygraph.to_variable(score)\n",
    "                # è®¡ç®—å‡ºç®—æ³•çš„å‰å‘è®¡ç®—ç»“æœ\n",
    "                _, _, scores_predict = model(usr_v, mov_v)\n",
    "                # è®¡ç®—loss\n",
    "                loss = fluid.layers.square_error_cost(scores_predict, scores_label)\n",
    "                avg_loss = fluid.layers.mean(loss)\n",
    "                if idx % 500 == 0:\n",
    "                    print(\"epoch: {}, batch_id: {}, loss is: {}\".format(epoch, idx, avg_loss.numpy()))\n",
    "                    \n",
    "                # æŸå¤±å‡½æ•°ä¸‹é™ï¼Œå¹¶æ¸…é™¤æ¢¯åº¦\n",
    "                avg_loss.backward()\n",
    "                opt.minimize(avg_loss)\n",
    "                model.clear_gradients()\n",
    "            # æ¯ä¸ªepoch ä¿å­˜ä¸€æ¬¡æ¨¡å‹\n",
    "            fluid.save_dygraph(model.state_dict(), './checkpoint/epoch'+str(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯åŠ¨è®­ç»ƒ\n",
    "with dygraph.guard():\n",
    "    use_poster, use_mov_title, use_mov_cat, use_age_job = True, True, True, True\n",
    "    model = Model('Recommend', use_poster, use_mov_title, use_mov_cat, use_age_job)\n",
    "    train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, params_file_path):\n",
    "    use_gpu = False\n",
    "    place = fluid.CUDAPlace(0) if use_gpu else fluid.CPUPlace()\n",
    "\n",
    "    with fluid.dygraph.guard(place):\n",
    "\n",
    "        model_state_dict, _ = fluid.load_dygraph(params_file_path)\n",
    "        model.load_dict(model_state_dict)\n",
    "        model.eval()\n",
    "\n",
    "        acc_set = []\n",
    "        avg_loss_set = []\n",
    "        for idx, data in enumerate(model.valid_loader()):\n",
    "            usr, mov, score_label = data\n",
    "            usr_v = [dygraph.to_variable(var) for var in usr]\n",
    "            mov_v = [dygraph.to_variable(var) for var in mov]\n",
    "\n",
    "            _, _, scores_predict = model(usr_v, mov_v)\n",
    "\n",
    "            pred_scores = scores_predict.numpy()\n",
    "            \n",
    "            avg_loss_set.append(np.mean(np.abs(pred_scores - score_label)))\n",
    "\n",
    "            diff = np.abs(pred_scores - score_label)\n",
    "            diff[diff>0.5] = 1\n",
    "            acc = 1 - np.mean(diff)\n",
    "            acc_set.append(acc)\n",
    "        return np.mean(acc_set), np.mean(avg_loss_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_path = \"./checkpoint/epoch\"\n",
    "for i in range(10):\n",
    "    acc, mae = evaluation(model, param_path+str(i))\n",
    "    print(\"ACC:\", acc, \"MAE:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part3:å°†æ˜ å°„åçš„ç”¨æˆ·ç‰¹å¾å’Œç”µå½±ç‰¹å¾ï¼Œé€šè¿‡ä¸¤è€…çš„ç›¸ä¼¼åº¦è®¡ç®—ç»“æœè¿›è¡Œæ¨è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "# åŠ è½½ç¬¬ä¸‰æ–¹åº“Pickleï¼Œç”¨æ¥ä¿å­˜Pythonæ•°æ®åˆ°æœ¬åœ°\n",
    "import pickle\n",
    "# å®šä¹‰ç‰¹å¾ä¿å­˜å‡½æ•°\n",
    "def get_usr_mov_features(model, params_file_path, poster_path):\n",
    "    use_gpu = False\n",
    "    place = fluid.CUDAPlace(0) if use_gpu else fluid.CPUPlace()\n",
    "    usr_pkl = {}\n",
    "    mov_pkl = {}\n",
    "    \n",
    "    # å®šä¹‰å°†listä¸­æ¯ä¸ªå…ƒç´ è½¬æˆvariableçš„å‡½æ•°\n",
    "    def list2variable(inputs, shape):\n",
    "        inputs = np.reshape(np.array(inputs).astype(np.int64), shape)\n",
    "        return fluid.dygraph.to_variable(inputs)\n",
    "    \n",
    "    with fluid.dygraph.guard(place):\n",
    "        # åŠ è½½æ¨¡å‹å‚æ•°åˆ°æ¨¡å‹ä¸­ï¼Œè®¾ç½®ä¸ºéªŒè¯æ¨¡å¼evalï¼ˆï¼‰\n",
    "        model_state_dict, _ = fluid.load_dygraph(params_file_path)\n",
    "        model.load_dict(model_state_dict)\n",
    "        model.eval()\n",
    "        # è·å¾—æ•´ä¸ªæ•°æ®é›†çš„æ•°æ®\n",
    "        dataset = model.Dataset.dataset\n",
    "\n",
    "        for i in range(len(dataset)):\n",
    "            # è·å¾—ç”¨æˆ·æ•°æ®ï¼Œç”µå½±æ•°æ®ï¼Œè¯„åˆ†æ•°æ®  \n",
    "            # æœ¬æ¡ˆä¾‹åªè½¬æ¢æ‰€æœ‰åœ¨æ ·æœ¬ä¸­å‡ºç°è¿‡çš„userå’Œmovieï¼Œå®é™…ä¸­å¯ä»¥ä½¿ç”¨ä¸šåŠ¡ç³»ç»Ÿä¸­çš„å…¨é‡æ•°æ®\n",
    "            usr_info, mov_info, score = dataset[i]['usr_info'], dataset[i]['mov_info'],dataset[i]['scores']\n",
    "            usrid = str(usr_info['usr_id'])\n",
    "            movid = str(mov_info['mov_id'])\n",
    "\n",
    "            # è·å¾—ç”¨æˆ·æ•°æ®ï¼Œè®¡ç®—å¾—åˆ°ç”¨æˆ·ç‰¹å¾ï¼Œä¿å­˜åœ¨usr_pklå­—å…¸ä¸­\n",
    "            if usrid not in usr_pkl.keys():\n",
    "                usr_id_v = list2variable(usr_info['usr_id'], [1, 1])\n",
    "                usr_age_v = list2variable(usr_info['age'], [1, 1])\n",
    "                usr_gender_v = list2variable(usr_info['gender'], [1, 1])\n",
    "                usr_job_v = list2variable(usr_info['job'], [1, 1])\n",
    "\n",
    "                usr_in = [usr_id_v, usr_gender_v, usr_age_v, usr_job_v]\n",
    "                usr_feat = model.get_usr_feat(usr_in)\n",
    "\n",
    "                usr_pkl[usrid] = usr_feat.numpy()\n",
    "            \n",
    "            # è·å¾—ç”µå½±æ•°æ®ï¼Œè®¡ç®—å¾—åˆ°ç”µå½±ç‰¹å¾ï¼Œä¿å­˜åœ¨mov_pklå­—å…¸ä¸­\n",
    "            if movid not in mov_pkl.keys():\n",
    "                mov_id_v = list2variable(mov_info['mov_id'], [1, 1])\n",
    "                mov_tit_v = list2variable(mov_info['title'], [1, 1, 15, 1])\n",
    "                mov_cat_v = list2variable(mov_info['category'], [1, 1, 6, 1])\n",
    "\n",
    "                mov_in = [mov_id_v, mov_cat_v, mov_tit_v, None]\n",
    "                mov_feat = model.get_mov_feat(mov_in)\n",
    "\n",
    "                mov_pkl[movid] = mov_feat.numpy()\n",
    "    \n",
    "    print(len(mov_pkl.keys()))\n",
    "    # ä¿å­˜ç‰¹å¾åˆ°æœ¬åœ°\n",
    "    pickle.dump(usr_pkl, open('./usr_feat.pkl', 'wb'))\n",
    "    pickle.dump(mov_pkl, open('./mov_feat.pkl', 'wb'))\n",
    "    print(\"usr / mov features saved!!!\")\n",
    "\n",
    "        \n",
    "param_path = \"./checkpoint/epoch7\"\n",
    "poster_path = \"./work/ml-1m/posters/\"\n",
    "get_usr_mov_features(model, param_path, poster_path)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”Ÿæˆç”¨æˆ·å­—å…¸\n",
    "def get_rating_info(path):\n",
    "        # è¯»å–æ–‡ä»¶é‡Œçš„æ•°æ®\n",
    "        with open(path, 'r') as f:\n",
    "            data = f.readlines()\n",
    "        # å°†æ•°æ®ä¿å­˜åœ¨å­—å…¸ä¸­å¹¶è¿”å›\n",
    "        rating_info = {}\n",
    "        for item in data:\n",
    "            item = item.strip().split(\"::\")\n",
    "            usr_id,movie_id,score = item[0],item[1],item[2]\n",
    "            if usr_id not in rating_info.keys():\n",
    "                rating_info[usr_id] = {movie_id:float(score)}\n",
    "            else:\n",
    "                rating_info[usr_id][movie_id] = float(score)\n",
    "        return rating_info\n",
    "rating_info=get_rating_info('ml-1m/ratings.dat')\n",
    "print(rating_info['1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data_path = \"ml-1m/movies.dat\"\n",
    "mov_info = {}\n",
    "# æ‰“å¼€ç”µå½±æ•°æ®æ–‡ä»¶ï¼Œæ ¹æ®ç”µå½±IDç´¢å¼•åˆ°ç”µå½±ä¿¡æ¯\n",
    "with open(movie_data_path, 'r', encoding=\"ISO-8859-1\") as f:\n",
    "    data = f.readlines()\n",
    "    for item in data:\n",
    "        item = item.strip().split(\"::\")\n",
    "        mov_info[str(item[0])] = item"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
